% acmlarge-sample.tex, dated 25th May 2012
% This is a sample file for ACM large trim journals
%
% Compilation using 'acmlarge.cls' - version 1.3, Aptara Inc.
% (c) 2011 Association for Computing Machinery (ACM)
%
% Questions/Suggestions/Feedback should be addressed to => "acmtexsupport@aptaracorp.com".
% Users can also go through the FAQs available on the journal's submission webpage.
%
% Steps to compile: latex, bibtex, latex latex
%
% For tracking purposes => this is v1.3 - May 2012

\documentclass[prodmode,acmtap]{acmlarge}

% Metadata Information
\acmVolume{2}
\acmNumber{3}
\acmArticle{1}
\articleSeq{1}
\acmYear{2010}
\acmMonth{5}

% Package to generate and customize Algorithm as per ACM style
\usepackage[ruled]{algorithm2e}
\SetAlFnt{\algofont}
\SetAlCapFnt{\algofont}
\SetAlCapNameFnt{\algofont}
\SetAlCapHSkip{0pt}
\IncMargin{-\parindent}
\renewcommand{\algorithmcfname}{ALGORITHM}


% Page heads
\markboth{D. Pineo and C. Ware}{Neural Modeling of Flow Rendering Effectiveness}

% Title portion
\title{Neural Modeling of Flow Rendering Effectiveness}
\author{DANIEL PINEO and COLIN WARE \affil{University of New Hampshire}}

\begin{abstract}
It has been previously proposed that understanding the mechanisms of
contour perception can provide a theory for why some flow-rendering
methods allow for better judgments of advection pathways than others.
In the present article, we develop this theory through a numerical
model of the primary visual cortex of the brain (Visual Area 1) where
contour enhancement is understood to occur according to most
neurological theories. We apply a two-stage model of contour
perception to various visual representations of flow fields evaluated
using the advection task of Laidlaw et al. [2001]. In the first
stage, contour {enhancement} is modeled based on Li's cortical model
[Li 1998]. In the second stage, a model of streamline {tracing} is
proposed, designed to support the advection task. We examine the
predictive power of the model by comparing its performance to that of
human subjects on the advection task with four different
visualizations. The results show the same overall pattern for humans
and the model. In both cases, the best performance was obtained with
an aligned streamline-based method, which tied with a LIC-based
method. Using a regular or jittered grid of arrows produced worse
results. The model yields insights into the relative strengths of
different flow visualization methods for the task of visualizing
advection pathways.
\end{abstract}

\category{H.5.2}{Information Interfaces and Presentation}{User
Interfaces}[Evaluation/\break methodology]
\category{H.1.2}{Models and Principles}{User/Machine Systems}[Human Information Processing]
\category{I.5.1}{Pattern\break Recognition}{Models}[Neural Nets]

\terms{Human Factors}
\keywords{Contour perception, flow visualization, perceptual theory, visual cortex, visualization}

\acmformat{Pineo, D. and Ware,  C. 2010.Neural Modeling of Flow Rendering Effectiveness.}

\begin{document}

\begin{bottomstuff}
This work is supported by the Widget Corporation Grant \#312-001.\\
Author's address: D. Pineo, Kingsbury Hall, 33 Academic Way, Durham,
N.H. 03824; email: dspineo@comcast.net; Colin Ware, Jere A. Chase
Ocean Engineering Lab, 24 Colovos Road, Durham, NH 03824; email: cware@ccom.unh.edu
\end{bottomstuff}
\maketitle

% Head 1
\section{Introduction}

Many techniques for 2D flow visualization have been developed and
applied. These include grids of little arrows, still the most common
for many applications, equally spaced streamlines
\cite{Turk1996,Jobard1997}, and line integral convolution (LIC)
\cite{Cabral1993}. But which is best and why? \citeN{Laidlaw2001}
showed that the ``which is best'' question can be answered by means
of user studies in which participants are asked to carry out tasks
such as tracing advection pathways or finding critical points in the
flow field. (Note: An advection pathway is the same as a streamline
in a steady flow field.) \citeN{Ware2008} proposed that the ``why''
question may be answered through the application of recent theories
of the way contours in the environment are processed in the visual
cortex of the brain. But Ware only provided a descriptive sketch
with minimal detail and no formal expression. In the present paper,
we show, through a numerical model of neural processing in the
cortex, how the theory predicts which methods will be best for an
advection path tracing task.

% Head 2
\subsection{The IBQ Approach in Image Quality Estimation}

The IBQ approach combined with psychometric methods has proven suitable,
especially for testing the performance of imaging devices or their
components and then returning this quality information to the product
development or evaluation stages. When the subjective changes in image
quality are multivariate, the technical parameters changing in the test
image are unknown or difficult to compute. However, the IBQ approach can be
used to determine the subjectively important quality dimensions with a wide
range of natural image material related to changes caused by different
devices or their components. In order to tune the image-processing
components for optimal performance, it is important to know what the
subjectively crucial characteristics that change in the perceived image
quality are as a function of the tuning parameters, or simply for different
components. Table I describes the problems caused by multivariate changes in
image quality and offers suggestions of how to approach them by using
different measurement methods that complement each other. The IBQ approach
can complement the psychometric approaches and objective measurements by
defining the subjective meaning of image quality attributes and
characteristics; in other words, it reveals how important they are for the
overall perceived quality. This information can then be used as guidance in
tuning, and no complex models are needed in order to understand the relation
between objective measures and subjective quality ratings.

% Table
\begin{table}[t]
\tbl{Multivariate Changes in Image Quality Attributes, the Relationship
of Psychometric and Objective Image Quality Estimations and the IBQ Approach}{%
\begin{tabular}{|l|p{8pc}|p{8pc}|p{12pc}|}
\hline
~PROBLEM   & \multicolumn{3}{l|}{{Estimating the performance when image
                                quality changes are multivariate}}\\\hline
{APPROACH} & {Objective measurements}    & \multicolumn{2}{|{c}|}{Subjective measurements}\\\cline{3-4}
           &                             & IBQ approach          & Psychometric approach\\\hline
GOAL       & Objective and computational
             measures for describing the
             changes in the images       & Definition of
                                           subjectively
                                           crucial image quality
                                           characteristics       & The amount of
                                                                   change in either
                                                                   the overall quality
                                                                   or a single attribute\\\hline
QUESTION   & What changes physically?    & What matters for the
                                           observer?             & How big is the perceived
                                                                   change?\\\hline
\end{tabular}}
\begin{tabnote}
The IBQ approach can help to determine the subjectively crucial
characteristics of an image and therefore to give weights to objective and
computational measures.
\end{tabnote}
\label{tab1}
\end{table}


Our basic rational is as follows. Tracing an advection pathway for a
particle dropped in a flow field is a perceptual task that can be
carried out with the aid of a visual representation of the flow.
The task requires that an individual attempts to trace a continuous
contour from some designated starting point in the flow until some
terminating condition is realized. This terminating condition might
be the edge of the flow field or the crossing of some designated
boundary. If we can produce a neurologically plausible model of
contour perception then this may be the basis of a rigorous theory of
flow visualization efficiency.
% description
\begin{description}
    \item[Identify] Characteristics of an object.
    \item[Locate] Absolute or relative position.
    \item[Distinguish] Recognize as the same or different.
    \item[Categorize] Classify according to some property (e.g.,  color, position, or shape).
    \item[Cluster] Group same or related objects together.
    \item[Distribution] Describe the overall pattern.
    \item[Rank] Order objects of like types.
    \item[Compare] Evaluate different objects with each other.
    \item[Associate] Join in a relationship.
    \item[Correlate] A direct connection.
\end{description}

\subsection{Conditions}
The reproduction of the gestures was performed in the presence or
absence of visual and auditory feedback, resulting in four (2 $\times$ 2) conditions.
% enumerate
\begin{enumerate}
\item Visual and auditory feedback (V\,$+$\,A).
\item Visual feedback, no auditory feedback (V).
\item Auditory feedback, no visual feedback (A).
\item No visual or auditory feedback (None).
\end{enumerate}
The order of the four conditions was randomized across participants.
% itemize
\begin{itemize}
    \item \textit{when} $+$ \textit{where} $\Rightarrow$
          \textit{what}: State the properties of an object or objects at a
          certain ~time, or set of times,  and a certain place, or set of places.
    \item \textit{when} $+$ \textit{what} $\Rightarrow$
          \textit{where}: State the location or set of locations.
    \item \textit{where} $+$ \textit{what} $\Rightarrow$
          \textit{when}: State the time or set of times.
\end{itemize}
When conducting a user study, the goal for the study is to measure
the suitability of the visualization in some sense. What is actually
measured is a fundamental question that we believe can be handled by
using the concepts of {effectiveness}, {efficiency},
and {satisfaction}. These three concepts are derived from the
ISO standard of usability 9241-11.
% quote
\begin{quote}
    Extent to which a product can be used by specified users to
    achieve specified goals with \textit{effectiveness},
    \textit{efficiency}, and \textit{satisfaction} in a specified context of use.
\end{quote}

The mechanisms of contour perception have been studied by
psychologists for at least 80 years, starting with the Gestalt
psychologists. A major breakthrough occurred with the work of Hubel
and Wiesel \citeyear{Hubel1962,Hubel1968} and from that time,
neurological theories of contour perception developed. In this
article, we show that a model of neural processing in the visual
cortex  can be used to predict which flow representation methods will
be better. Our model has two stages. The first is a contour
enhancement model. Contour enhancement is achieved through lateral
connections between nearby local edge detectors. This produces a
neural map in which continuous contours have an enhanced
representation. The model or cortical processing we chose to apply is
adapted from \citeN{Li1998a}. The second stage is a contour
integration model. This represents a higher level cognitive process
whereby a pathway is traced.
% Enunciations
\begin{theorem}
For a video sequence of $n$ frames, an optimal approach based on
dynamic programming can retrieve all levels of key frames together
with their temporal boundaries in O($n^4$) times.
\end{theorem}

We apply the model to a set of 2D flow visualization methods that
were previously studied by \citeN{Laidlaw2001}. This allows us to
carry out a qualitative comparison between the model and how humans
actually performed. We evaluated the model against human performance
in an experiment in which humans and the model performed the same task.

Our article is organized as follows. First we summarize what is
known about the cortical processing of contours and introduce Li's
\citeyear{Li1998a} model of the cortex. Next we show how a slightly
modified version of Li's model differentially enhances various flow
rendering methods. Following this, we develop a perceptual model of
advection tracing and show how it predicts different outcomes for an
advection path-tracing task based on the prior work of
\citeN{Laidlaw2001}. Finally we discuss how this work relates to
other work that has applied perceptual modeling to data visualization
and suggest other uses of the general method.

% Figure
\begin{figure}[tp]
\centering
\includegraphics{acmlarge-mouse}
\caption{Neurons are arranged in V1 in a column architecture. Neurons
in a particular column respond preferentially to the same edge
orientation. Moving across the cortex (by a minute amount) yields
columns responding to edges having different orientations. A
hypercolumn is a section of cortex that represents a complete set of
orientations for a particular location in space.}
\label{corticalarchitecturefig}
\end{figure}

\section{Cortical Processing of Contours}
Visual information passes along the optic nerve from the retina of
the eye where it is relayed, via a set of synaptic junctions in the
midbrain lateral geniculate nucleus, to the primary visual cortex at
the back or the brain (Visual Area 1 or V1). It has been known since
the Hubel and Wiesel's work in the 60s that the visual cortex
contains billions of neurons that are sensitive to oriented edges and
contours in the light falling on the retina. Such neurons have
localized receptive fields each responding to the orientation
information contained within the light imaged in a small patch of
retina. A widely used mathematical model of a V1 neuron's receptive
field is the Gabor function \cite{Daugman1985}:
\begin{equation}
\label{gaboreqn}
Gabor(u,v,\lambda,\theta,\phi,\sigma,\gamma)=e^{-\frac{u'^{2}+
\gamma^{2}v'^{2}}{2\sigma^{2}}}cos(2\pi\frac{u'}{\lambda}+\phi).
\end{equation}

Hubel and Wiesel \citeyear{Hubel1962,Hubel1968} found that neurons
responding to similar orientations were clustered together in a
structure they called a column which extended from the surface of the
visual cortex to the white matter (see Figure
\ref{corticalarchitecturefig}). Later, they and other researchers
discovered hypercolumn structures consisting of thousands of neurons
all responding to the same area of visual space and selecting for a
range of orientations. Overall, V1 contains a topographic map of the
visual field having the property that every part of the retinal image
is processed in parallel for all orientations. These orientation
selective neurons have provided the basis for all subsequent theories
of contour and edge detection.

There remains the problem of how the output of orientation sensitive
neurons, each responding to different parts of a visual contour,
becomes combined to represent the whole contour. Part of the solution
appears to be a contour enhancement mechanism. \citeN{Field1993}
examined the human's ability to perceive a contour composed of
discrete oriented elements. They placed a contour composed of
separated Gabor patches, among a field of randomly orientated Gabor
patches. Contours were detected when the patches were smoothly
aligned. They were not detected when there was misalignment. This
work suggests that there is some manner of lateral coupling among the
visual elements involved in perceiving the Gabor patches in the
contour. These researchers have suggested that similarly oriented
aligned contours mutually excite one another, while they inhibit
other neurons that are nearby (Figure~\ref{neuronalignmentfig}).

\begin{figure}[tp]
\centering
\includegraphics{acmlarge-mouse}
\caption{Neurons whose receptive fields are aligned along a
continuous contour mutually reinforce each other. They inhibit nearby
neurons with a similar orientation sensitivity.}
\label{neuronalignmentfig}
\end{figure}

\section{Li's V1 Model}
Based on the observed organization of the neurons in the visual
cortex by Hubel and Wiesel \citeyear{Hubel1962,Hubel1968} and the
experimental evidence by \citeN{Field1993}, Zhaoping Li constructed a
simplified model of the behavior of V1 neurons and examined the
model's ability to integrate contours across multiple V1 neurons.
The model is introduced briefly here, and described in more detail in
\citeN{Li1998a}. In Li's model, the cortex is approximated by a set
of hypercolumns arranged in a hexagonal grid. Each hexagonal cell has
12 orientation-selective neuron pairs oriented in 15-degree
increments. One of the main simplifications embodied in Li's model is
that it fails to incorporate the way the mammalian visual systems
scales with respect to the fovea. Real neural architectures have much
smaller receptive fields near the fovea at the center of vision than
at the edges of the visual field.
The neurons in each hex cell were grouped into excitatory and
inhibitory pairs responding to an edge of a particular orientation at
that location. Thus there were a total of 24 neurons per cell. The
firing rates of both the inhibitory and excitatory neurons were
modeled with real values. The neuron pairs affected neighboring
neuron pairs via a transfer function that depended on the alignment
of the edge selectivity orientations. Neuron pairs that were aligned
with one another exhibited an excitatory effect on each other, while
pairs that were not aligned inhibited each other. Finally, Li's model
also contains feedback pathways for higher-level visual areas to
influence individual neurons.

In our implementation, the mapping of the hexagonal grid to the image
space was such that the hex centers were separated by 10 pixels. For
the V1 neuron response, we used the Gabor function (Eq.
(\ref{gaboreqn})) with a wavelength, $\lambda$, of 21 pixels, a
$\sigma$ of 7 pixels, and an aspect ratio, $\gamma$, of 1.

\section{Streamline Tracing Algorithm}
\citeN{Laidlaw2001} compared the effectiveness of
visualization techniques by presenting test subjects with the task of
estimating where a particle placed in the center of a flow field
would exit a circle. Six different flow-field visualization methods
were assessed by comparing the difference between the actual exit
numerically calculated and the estimation of the exit by the human
subjects. Laidlaw et~al.'s experiment was carried out on humans but,
in our work, we apply this evaluation technique to humans as well as
to our model of the human visual system and use a streamline tracing
algorithm to trace the path of the particle.

We use the term streamline tracing to describe the higher level
process that must exist for people to judge a streamline pathway.
We call it streamline tracing because the task seems to require the
user to make a series of judgments, starting at the center, whereby
the path of a particle dropped in the center is integrated in a
stepwise pattern to the edge of the field. Though many algorithms
exist in the machine vision literature for contour tracing, we found
these to be inappropriate for use in this application. Contour
tracing algorithms are generally designed to trace out the boundary
of some shape but a streamline tracing algorithm must also be able
able to produce a streamline in a field of disconnected contours,
such as is the case with the regular arrows. The streamline to be
traced will often not follow a visible contour but instead be locate
between contours, and will sometimes pass through areas devoid of
visual elements. Thus we developed a specialized algorithm that is
capable of tracing streamlines that do not necessarily correspond to
the boundary of any shape but can pass between visual contours.

Perception is a combination of top-down and bottom-up processes.
Bottom-up processes are driven by information on the retina and are
what is simulated by Li's model \citeyear{Li1998a}. Top-down
processes are much more varied and are driven in the brain by
activation from regions in the frontal and temporal cortex that are
known to be involved in the control of pattern identification and
attention \cite{Lund2001}. All of the flow visualizations evaluated
by \citeN{Laidlaw2001}, except for LIC, contain symbolic information
regarding the direction of flow along the contour elements (e.g. an
arrowhead). In a perpetual/cognitive process this would be regarded
as a top-down influence. At present our model does not deal with
symbolic direction information but it does do streamline tracing once
set in the right general direction.

Streamline tracing is a combination of top-down and bottom-up
processes. Broadly speaking, top-down processes reflect task demands
and the bottom-up processes reflect environmental information. In our
case, the bottom-up information comes from the different types of
visualization, while the top-down information is an attempt to model
the cognitive process of streamline pathway tracing. Contour
integration was modeled using the following iterative algorithm.

% Algorithm
\medskip
\begin{algorithm}[H]
\SetAlgoNoLine
$current\_position \leftarrow$ center \\
$current\_direction \leftarrow$ up \\
$current\_position$ is inside circle \\
\While{$current\_position$ is inside circle,}{
  $neighborhood \leftarrow$ all grid hexes within two hexes from $current\_position$ \\
  \For{ each $hex$ in $neighborhood$, }{
  \For{each $neuron$ in $hex$}{
  convert $neuron\_orientation$ to $vector$ \\
  scale $vector$ by $neuron\_excitation$ \\
  $vector\_sum \leftarrow vector\_sum + vector$}}

  normalize $vector\_sum$ \\
  $current\_position \leftarrow current\_position + vector\_sum$ \\
  $current\_direction \leftarrow vector\_sum$ \\
return $current\_position$ \\
}
    \caption{Iterative Algorithm}
    \label{alg:one}
  \end{algorithm}
\medskip

The algorithm maintains a context that contains a current position
and direction. Initially, the position is the center, and the
direction set to upward. This context models the higher-order,
top-down influence on the algorithm that results from the task
requirements (tracing from the center dot) and the directionality
which in our experiment was set to be always in an upwardly trending direction.

The algorithm traces the contour by repeatedly estimating the flow
direction at the $current\_position$ and moving the position a small
distance (.5 hex radii) in that direction. The flow direction is
calculated from the neural responses in the local neighborhood of the
$current\_position$. The excitation of each neuron is used to
generate a vector whose length is proportional to the strength of the
response and whose orientation is given by the receptive field
orientation. Because receptive field orientations are ambiguous as to
direction (for any vector aligned with the receptive field, its
negative is similarly aligned). The algorithm chose the vector most
closely corresponding to the vector computed on the previous
iteration. Vectors are computed for all neurons in hypercolumns
within a 2-hexes radius of the current position; they are summed and
normalized to generate the next $current\_direction$.

Some changes were made from the method published by
\citeN{Pineo2008}. Previously, the algorithm considered only a single
hex cell at each iteration of the algorithm. We found that this would
occasionally cause unrealistically large errors in streamline
tracing. For example, on visualizations with arrowheads, the neural
network might yield a very strong edge orthogonal to the flow field
positioned at the back of an arrowhead. If the algorithm considered
only the edges at this point, it may make a significant error,
despite the edges in nearby positions indicating the correct
direction. We felt that creating an average over $neighborhood$ was
the more correct approach, and we found closer agreement with human
performance with this change.

\subsection{Qualitative Evaluation}
Four different flow visualization methods were used in our evaluation
of the theory. These were implementations of four of the six used by
\citeN{Laidlaw2001}. We chose to investigate a regular arrow grid
because it is still the most commonly used in practice and a jittered
arrow grid because of the arguments that have been made that this
should improve perceptual aliasing problems \cite{Turk1996}. We added
Line Integral Convolution (LIC) because of its widespread advocation
by the visualization community \cite{Cabral1993} and head-to-tail
aligned streaklets because of Laidlaw et al.'s finding that is was
the best and the theoretical arguments in support of this method
\cite{Ware2008}. Note that Laidlaw et al. used Turk and Banks
algorithm to achieve aligned arrows on equally spaced streamlines
while we used Jobard and Lefer's \citeyear{Jobard1997} method to
achieve the same effect and we used streaklets without an arrowhead
\cite{Fowler1989}.

\begin{figure}[tp]
    \begin{minipage}[t]{0.45\linewidth}
        \centering
        \includegraphics{acmlarge-mouse}
        \caption{Regular arrows.}
        \label{regularfig}
    \end{minipage}
    \hspace{0.1\linewidth}
    \begin{minipage}[t]{0.45\linewidth}
        \centering
        \includegraphics{acmlarge-mouse}
        \caption{Jittered arrows.}
        \label{jitteredfig}
    \end{minipage}
\end{figure}

\begin{figure}[tp]
    \begin{minipage}[t]{0.45\linewidth}
        \centering
        \includegraphics{acmlarge-mouse}
        \caption{Closeup of neural response to arrowheads.}
        \label{ortharrowheadfig}
    \end{minipage}
    \hspace{0.1\linewidth}
    \begin{minipage}[t]{0.45\linewidth}
        \centering
        \includegraphics{acmlarge-mouse}
        \caption{Closeup of neural response to aligned streaklets.}
        \label{alignedcloseupfig}
    \end{minipage}
\end{figure}


V1 is known to have detectors at different scales. However, to make
the problem computationally tractable we chose only a single scale
for the V1 and designed the data visualizations with elements scaled
such that they were effectively detected by the gabor filter used by
the model. The widths of the arrows and streaklets were chosen to be
smaller than the central excitatory band of the gabor filter. This
allowed the edge to be detected even if not precisely centered on the
receptive field of the neuron. The spatial frequency of the LIC
visualization is defined by the texture over which the vector field
is convoluted. Our texture was created by generating a texture of
random white noise of one-third the necessary size and scaling it up
via. interpolation. The resulting spacial frequency of the LIC
visualization was of a scale that was effectively detected by the
gabor filters of the model.

% Head 3
\subsubsection{Regular Arrows (Figure \ref{regularfig})} This
visualization is produced by placing arrow glyphs at regular
spacings. The magnitude of the vector field is indicated by the arrow
length, and the flow direction by the arrow head. The grid underlying
the regular arrows is apparent to humans, but the edge weights of the
model show no obvious signs of being negatively affected. In fact,
the regularity ensures that the arrows are well spaced, preventing
any false edge responses that might be produced by the interference
of multiple arrows. We can expect that nontangential edge responses
will be produced by the arrowheads and these will lead to errors in
the streamline advection task.

% Head 4
\paragraph{Jittered arrows (Figure \ref{jitteredfig})}
This visualization is similar to the regular arrows, but the arrows
are moved a small random distance from the regular locations. While
composed of the same basic elements as the regular grid, we see
instances where nearby arrows interfere with each other and produce
edge responses nontangential to the flow direction. Also, as with
gridded arrows, the arrowheads will excite neurons with orientation
selectivity nontangential to the flow. This can be seen in
Figure~\ref{ortharrowheadfig}. In this figure, we can see orthogonal
neural excitation to each side of the upper arrow, caused by the back
edge of the arrowhead (blue circles). We can also see excitation
caused by the interference of two arrows at the bottom right (green
circle). These nontangential responses are much stronger than those
found in the aligned streaklets visualization (Figure \ref{alignedcloseupfig}).


\section{Discussion}
The overall agreement between the pattern of results for human
observers and the V1-based model provides strong support of the
perceptual theory we outlined in the introduction. The aligned arrows
style of visualization produced clear chains of mutually reinforcing
neurons along the flow path in the representation, making the flow
pathway easy to trace as predicted by theory.

The fact that LIC produced results as good as the equally spaced
streamlines was something of a surprise, and this lends support to
its popularity within the visualization community. While it did not
produce as much neuron excitation as the aligned arrows method, this
was offset by the lack of nontangential edge responses produced by
glyph-based visualizations. However, its good performance was
achieved only because our evaluation method ignored the directional
ambiguity inherent in this method. \citeN{Laidlaw2001} found this
method to be the worst and there is little doubt that had we allowed
flow in any direction, up or down, human observers would have found
pathways with close to 180 degrees of error half of the time.

The performance of both the model and the human test subjects is
likely to be highly dependent on the underlying vector field used.
As described in Section 5.1.6, the vector field was generated by
interpolating between an 8x8 grid of random, but generally upward
pointing vectors. A consequence of this is that when adjacent vectors
in this grid point somewhat toward each other, the vector field forms
an area of convergence. This convergence area tends to funnel
neighboring streamline paths together, reducing error in streamline
tracing (Figure \ref{regularfig} is an example of this).  Thus, the
overall accuracies of both the model and human subjects may be higher
than might be might be observed using a vector field without such convergence zones.

We were surprised that the computer algorithm actually did better at
the task than human observers. One reason for this may have been that
humans would have to make saccadic eye movements to trace a path,
whereas the computer did not. For the patterns we used, it is likely
that the observers had to make fixations on several successive parts
of a path, and errors may have accumulated as they resumed a trace
from a previous fixation. Nevertheless, we feel that the algorithm
could easily be adjusted to make it give results closer to human
subjects. A more sophisticated approach would be to simulate eye fixations.

The model we applied is a considerable simplification over what
actually occurs. It only uses the simplest model of the simplest
orientation sensitive neurons, and fails to include cortical
magnification, among other shortcomings. Real cortical receptive
fields are not arranged in a rigid hexagonal grid as they are in Li's
model. Furthermore, the neurons of V1 respond to many frequencies,
however our model only uses one in its present form. In addition,
besides the so-called simple cells modeled by \citeN{Li1998a}, other
neurons in V1 and V2 called complex and hypercomplex cells all have
important functions. For example, end-stopped cell respond best to a
contour that terminates in the receptive field and understanding
these may be important in showing how the direction of flow along a
contour can be unambiguously shown. Moreover, visual information is
processed through several stages following the primary cortex,
including V2, V4 and the IT cortex. Each of these appears to abstract
more complex, less localized patterns. Researchers are far from
having sufficient information to model the operations of these stages
all of which may have a role in tracing contours. Nevertheless, the
results are compelling and there are advantages in having a
relatively simple model. We have plans to add some of these more
complex functions in future versions of the model.



% Appendix
\appendix
\section*{APPENDIX}
\setcounter{section}{1}


With closest point to a given set of lines we intend the point
having the minimum Euclidean distance with respect to those lines.
Typically, this problem is formulated using Pl\"{u}cker coordinates.
Instead, here we compute this point by solving the problem in a closed
form, since the resulting matrices are not ill-conditioned in our
case. More precisely, by indicating the set of $n$ lines with
%
\begin{equation}
  L = \left \{ l_i = O_i + t \vec{d}_i | \, t \in {R} \right \} \,\,\, i = 1
  \ldots n,
  \label{eq:setoflines}
\end{equation}
%
where $O_i$ is the origin of the $i$th line and $\vec{d}_i$ is the
corresponding direction (normalized), we found the closest point by
minimizing
%
\begin{equation}
  p = \arg \min_{x} \sum_{i=1}^{n} d(x,l_i).
  \label{eq:problemstatement}
\end{equation}
%
The distance $d(x, l_i)$ can be written as
%
\begin{equation}
  d(x , l_i)^2 = (x - O_i) \left [ \textbf{I} - \vec{d_i} \vec{d_i}^T \right ] (x - O_i).
  \label{eq:distance}
\end{equation}
%
The minimization is obtained by substituting (\ref{eq:distance}) in
(\ref{eq:problemstatement}), and imposing the derivative to zero.
%
After some simple algebra, we obtain the final formulation:
%
\begin{equation}
  p = \left [ n \textbf{I} - \sum_{i=1}^{n} \vec{d_i} \vec{d_i}^T
  \right ]^{-1} \sum_{i=1}^{n} \left [ \textbf{I} - \vec{d_i} \vec{d_i}^T \right ] O_i.
  \label{eq:closedform}
\end{equation}
% Bibliography
\bibliographystyle{acmlarge}
\bibliography{acmlarge-sam}

% History dates
\received{February 2009}{July 2009}{October 2009}


\elecappendix


\section{Analysis of Invalid Trials}
\label{invalid}

\subsection{Results}


Invalid trials were previously defined as those trials in which the
subject pressed the space bar to end the trial without first bringing
the virtual finger to a stop. The number of invalid trials for each
subject is presented by feedback condition in Figure~12. Due to the
irregular distribution of the data, no significance test was run.
However, the figure shows two notable features. First, Subject 6 had
more invalid trials than any other subject. Second, more invalid
trials occurred under the proprioceptive-only (NV$+$P) feedback
condition than any other.



\subsection{Discussion}

Although the number of invalid trials is not directly related to task
performance, we now consider any trends that may be seen in this
information. No statistical tests were done with this data, but some
inferences can be drawn from the invalid trial counts in Figure 12.
The only obvious trend is that the NV$+$P condition appears to have
the most invalid trials, which is the case for all but two subjects.
In the post-experiment survey, one subject commented on this trend,
saying that with only proprioceptive motion feedback it was hard to
tell if the finger was moving or not. This might be a result of a
larger threshold for absolute motion detection for proprioceptive
feedback than for visual feedback. This difficulty in stopping the
finger did not appear to affect the ease of use ratings provided by
subjects, as no correlation was observed with invalid trial counts.

It is interesting to note that the no-feedback condition (NV$+$NP)
had fewer invalid trials than the proprioceptive-only condition
(NV$+$P), especially in light of the findings of Ghez et al. [1990]
that deafferented individuals tend to display endpoint drift in
non-sighted targeted reaching movements (equivalent to NV$+$NP
condition) while neurologically normal individuals do not (equivalent
to NV$+$P condition). A notable difference between our study and the
study by Ghez et al.\ is the availability of kinesthetic feedback
from the thumb pressing on the force sensor, which indicates the
magnitude of the applied force, that is, the movement command in our
study. Thus, under the no-feedback condition, subjects could use this
information to learn to apply grasping forces within the dead zone to
stop finger movement. When motion feedback is available, subjects are
likely focusing more on the feedback than on the forces applied,
since the feedback allows them to achieve better accuracy. Thus, at
the end of a trial, subjects are most likely using this feedback as
an indicator of zero velocity rather than attending to the applied
force. When visual feedback is available, it is easy to determine
whether the finger is moving or not; however, when only
proprioceptive feedback is available, the finger can be moving slowly
without the subject being aware of its motion. This explanation would
result in a larger number of failed trials for the NV$+$P condition
than for any other, as observed.

\end{document}

